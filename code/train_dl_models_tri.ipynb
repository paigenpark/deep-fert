{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning for Fertility Prediction (DLMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os as os\n",
    "tfkl = tf.keras.layers\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_functions' from '/Users/paigepark/Desktop/repos/deep-fert/code/training_functions.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import training_functions\n",
    "import importlib\n",
    "\n",
    "importlib.reload(training_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asfr_training = np.loadtxt('../data/asfrTR_training.txt')\n",
    "asfr_test = np.loadtxt('../data/asfrTR_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75936, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asfr_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geos_key = np.load('../data/geos_key.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Country Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models are those used in the paper to produce all of main figures/table in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "train_prepped = training_functions.prep_data(asfr_training, mode=\"train\", changeratetolog=True)\n",
    "test_prepped = training_functions.prep_data(asfr_test, mode=\"test\", changeratetolog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proper geography input dimension for model set up \n",
    "unique_vals = tf.unique(asfr_training[:, 0]).y\n",
    "country_geo_dim = np.array(tf.size(unique_vals)).item()\n",
    "country_geo_dim = country_geo_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.e+00, 1.e-05, 2.e-05])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.partition(np.unique(asfr_training[:,3]), 3)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 1.0445 - val_loss: 0.7196 - learning_rate: 1.0000e-03\n",
      "Epoch 2/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.3542 - val_loss: 0.5649 - learning_rate: 1.0000e-03\n",
      "Epoch 3/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2608 - val_loss: 0.4133 - learning_rate: 1.0000e-03\n",
      "Epoch 4/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2248 - val_loss: 0.3633 - learning_rate: 1.0000e-03\n",
      "Epoch 5/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2041 - val_loss: 0.3035 - learning_rate: 1.0000e-03\n",
      "Epoch 6/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1872 - val_loss: 0.3313 - learning_rate: 1.0000e-03\n",
      "Epoch 7/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1763 - val_loss: 0.3021 - learning_rate: 1.0000e-03\n",
      "Epoch 8/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1663 - val_loss: 0.2473 - learning_rate: 1.0000e-03\n",
      "Epoch 9/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1600 - val_loss: 0.2341 - learning_rate: 1.0000e-03\n",
      "Epoch 10/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1534 - val_loss: 0.2666 - learning_rate: 1.0000e-03\n",
      "Epoch 11/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1490 - val_loss: 0.2382 - learning_rate: 1.0000e-03\n",
      "Epoch 12/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1461 - val_loss: 0.2267 - learning_rate: 1.0000e-03\n",
      "Epoch 13/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1397 - val_loss: 0.2445 - learning_rate: 1.0000e-03\n",
      "Epoch 14/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1366 - val_loss: 0.2589 - learning_rate: 1.0000e-03\n",
      "Epoch 15/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1326 - val_loss: 0.2021 - learning_rate: 1.0000e-03\n",
      "Epoch 16/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1285 - val_loss: 0.2410 - learning_rate: 1.0000e-03\n",
      "Epoch 17/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1259 - val_loss: 0.2357 - learning_rate: 1.0000e-03\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1258 - val_loss: 0.2045 - learning_rate: 1.0000e-03\n",
      "Epoch 19/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1194 - val_loss: 0.2260 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1170 - val_loss: 0.2265 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1161 - val_loss: 0.2220 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1158 - val_loss: 0.1993 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1134 - val_loss: 0.2007 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 0.1129 - val_loss: 0.2137 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1136 - val_loss: 0.2149 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1133 - val_loss: 0.2070 - learning_rate: 1.5625e-05\n",
      "Epoch 27/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1112 - val_loss: 0.2032 - learning_rate: 1.5625e-05\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1136 - val_loss: 0.2077 - learning_rate: 1.5625e-05\n",
      "Epoch 29/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1127 - val_loss: 0.2104 - learning_rate: 3.9063e-06\n",
      "Epoch 30/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1142 - val_loss: 0.1972 - learning_rate: 3.9063e-06\n",
      "Epoch 31/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1123 - val_loss: 0.2000 - learning_rate: 3.9063e-06\n",
      "Epoch 32/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1137 - val_loss: 0.2079 - learning_rate: 3.9063e-06\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1131 - val_loss: 0.2052 - learning_rate: 3.9063e-06\n",
      "Epoch 34/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1130 - val_loss: 0.2256 - learning_rate: 9.7656e-07\n",
      "Epoch 35/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1132 - val_loss: 0.2048 - learning_rate: 9.7656e-07\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1114 - val_loss: 0.2050 - learning_rate: 9.7656e-07\n",
      "Epoch 37/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1137 - val_loss: 0.2144 - learning_rate: 2.4414e-07\n",
      "Epoch 38/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1121 - val_loss: 0.2235 - learning_rate: 2.4414e-07\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1143 - val_loss: 0.2126 - learning_rate: 2.4414e-07\n",
      "Epoch 40/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1122 - val_loss: 0.2124 - learning_rate: 6.1035e-08\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\u001b[1m2373/2373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246us/step\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step\n"
     ]
    }
   ],
   "source": [
    "model_country, loss_info_country = training_functions.run_deep_model(train_prepped, test_prepped, country_geo_dim, \n",
    "                                                                        epochs=50, \n",
    "                                                                        steps_per_epoch=1405, \n",
    "                                                                        lograte=True)\n",
    "\n",
    "training_input_features = (tf.convert_to_tensor((asfr_training[:,1] - 1950) / (2015-1950), dtype=tf.float32),  # Normalized year\n",
    "                        tf.convert_to_tensor(asfr_training[:,2], dtype=tf.float32),  # Age\n",
    "                        tf.convert_to_tensor(asfr_training[:,0], dtype=tf.float32))  # Geo\n",
    "\n",
    "test_input_features = (tf.convert_to_tensor((asfr_test[:,1] - 1950) / (2015-1950), dtype=tf.float32),  # Normalized year\n",
    "                    tf.convert_to_tensor(asfr_test[:,2], dtype=tf.float32),  # Age\n",
    "                    tf.convert_to_tensor(asfr_test[:,0], dtype=tf.float32))  # Geo\n",
    "\n",
    "training_predictions = model_country.predict(training_input_features)\n",
    "\n",
    "test_predictions = model_country.predict(test_input_features)\n",
    "\n",
    "inputs = np.delete(asfr_training, 3, axis=1)\n",
    "training_predictions = np.column_stack((inputs, training_predictions))\n",
    "inputs_test = np.delete(asfr_test, 3, axis=1)\n",
    "test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "np.savetxt(f\"../data/dl_fitted_explore.txt\", training_predictions)\n",
    "np.savetxt(f\"../data/dl_forecast_explore.txt\", test_predictions)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "production model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 1.1511 - val_loss: 0.8871 - learning_rate: 1.0000e-03\n",
      "Epoch 2/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.4694 - val_loss: 0.5682 - learning_rate: 1.0000e-03\n",
      "Epoch 3/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.3398 - val_loss: 0.3622 - learning_rate: 1.0000e-03\n",
      "Epoch 4/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2774 - val_loss: 0.3325 - learning_rate: 1.0000e-03\n",
      "Epoch 5/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 0.2473 - val_loss: 0.3193 - learning_rate: 1.0000e-03\n",
      "Epoch 6/50\n",
      "1405/1405 - 4s - 2ms/step - loss: 0.2246 - val_loss: 0.3116 - learning_rate: 1.0000e-03\n",
      "Epoch 7/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 0.2096 - val_loss: 0.3270 - learning_rate: 1.0000e-03\n",
      "Epoch 8/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1960 - val_loss: 0.2975 - learning_rate: 1.0000e-03\n",
      "Epoch 9/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 0.1865 - val_loss: 0.3052 - learning_rate: 1.0000e-03\n",
      "Epoch 10/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 0.1795 - val_loss: 0.2797 - learning_rate: 1.0000e-03\n",
      "Epoch 11/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 0.1723 - val_loss: 0.2718 - learning_rate: 1.0000e-03\n",
      "Epoch 12/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1654 - val_loss: 0.2706 - learning_rate: 1.0000e-03\n",
      "Epoch 13/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 0.1580 - val_loss: 0.3274 - learning_rate: 1.0000e-03\n",
      "Epoch 14/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1547 - val_loss: 0.2732 - learning_rate: 1.0000e-03\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1405/1405 - 3s - 2ms/step - loss: 0.1503 - val_loss: 0.2982 - learning_rate: 1.0000e-03\n",
      "Epoch 16/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1421 - val_loss: 0.2855 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1403 - val_loss: 0.2566 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1390 - val_loss: 0.2777 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1390 - val_loss: 0.2423 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1395 - val_loss: 0.2534 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1369 - val_loss: 0.2639 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1354 - val_loss: 0.2783 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1337 - val_loss: 0.2694 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1343 - val_loss: 0.2539 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1334 - val_loss: 0.2677 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1349 - val_loss: 0.2639 - learning_rate: 1.5625e-05\n",
      "Epoch 27/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1332 - val_loss: 0.2587 - learning_rate: 1.5625e-05\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1329 - val_loss: 0.2603 - learning_rate: 1.5625e-05\n",
      "Epoch 29/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1345 - val_loss: 0.2560 - learning_rate: 3.9063e-06\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\u001b[1m2373/2373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257us/step\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step\n",
      "Iteration 1 complete\n",
      "Epoch 1/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 1.0752 - val_loss: 0.6866 - learning_rate: 1.0000e-03\n",
      "Epoch 2/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.4388 - val_loss: 0.4708 - learning_rate: 1.0000e-03\n",
      "Epoch 3/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.3178 - val_loss: 0.3399 - learning_rate: 1.0000e-03\n",
      "Epoch 4/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2693 - val_loss: 0.3720 - learning_rate: 1.0000e-03\n",
      "Epoch 5/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2412 - val_loss: 0.2924 - learning_rate: 1.0000e-03\n",
      "Epoch 6/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2225 - val_loss: 0.2885 - learning_rate: 1.0000e-03\n",
      "Epoch 7/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2067 - val_loss: 0.2717 - learning_rate: 1.0000e-03\n",
      "Epoch 8/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1961 - val_loss: 0.2914 - learning_rate: 1.0000e-03\n",
      "Epoch 9/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1867 - val_loss: 0.3020 - learning_rate: 1.0000e-03\n",
      "Epoch 10/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1791 - val_loss: 0.2547 - learning_rate: 1.0000e-03\n",
      "Epoch 11/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1710 - val_loss: 0.2618 - learning_rate: 1.0000e-03\n",
      "Epoch 12/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1659 - val_loss: 0.2599 - learning_rate: 1.0000e-03\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1605 - val_loss: 0.2724 - learning_rate: 1.0000e-03\n",
      "Epoch 14/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1523 - val_loss: 0.2646 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1494 - val_loss: 0.2421 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1496 - val_loss: 0.2663 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1478 - val_loss: 0.2431 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1471 - val_loss: 0.2415 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1452 - val_loss: 0.2501 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1452 - val_loss: 0.2358 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1446 - val_loss: 0.2393 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1436 - val_loss: 0.2465 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1420 - val_loss: 0.2606 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1409 - val_loss: 0.2475 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1392 - val_loss: 0.2468 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1386 - val_loss: 0.2466 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1377 - val_loss: 0.2346 - learning_rate: 1.5625e-05\n",
      "Epoch 28/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1398 - val_loss: 0.2462 - learning_rate: 1.5625e-05\n",
      "Epoch 29/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1397 - val_loss: 0.2431 - learning_rate: 1.5625e-05\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1378 - val_loss: 0.2516 - learning_rate: 1.5625e-05\n",
      "Epoch 31/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1369 - val_loss: 0.2548 - learning_rate: 3.9063e-06\n",
      "Epoch 32/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1380 - val_loss: 0.2261 - learning_rate: 3.9063e-06\n",
      "Epoch 33/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1385 - val_loss: 0.2432 - learning_rate: 3.9063e-06\n",
      "Epoch 34/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1388 - val_loss: 0.2434 - learning_rate: 3.9063e-06\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1382 - val_loss: 0.2518 - learning_rate: 3.9063e-06\n",
      "Epoch 36/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1394 - val_loss: 0.2360 - learning_rate: 9.7656e-07\n",
      "Epoch 37/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1385 - val_loss: 0.2451 - learning_rate: 9.7656e-07\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1399 - val_loss: 0.2449 - learning_rate: 9.7656e-07\n",
      "Epoch 39/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1389 - val_loss: 0.2525 - learning_rate: 2.4414e-07\n",
      "Epoch 40/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1372 - val_loss: 0.2494 - learning_rate: 2.4414e-07\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1380 - val_loss: 0.2480 - learning_rate: 2.4414e-07\n",
      "Epoch 42/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1380 - val_loss: 0.2545 - learning_rate: 6.1035e-08\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "\u001b[1m2373/2373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244us/step\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step\n",
      "Iteration 2 complete\n",
      "Epoch 1/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 1.1352 - val_loss: 0.8383 - learning_rate: 1.0000e-03\n",
      "Epoch 2/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.4669 - val_loss: 0.6086 - learning_rate: 1.0000e-03\n",
      "Epoch 3/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.3492 - val_loss: 0.4319 - learning_rate: 1.0000e-03\n",
      "Epoch 4/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2801 - val_loss: 0.3346 - learning_rate: 1.0000e-03\n",
      "Epoch 5/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2475 - val_loss: 0.3441 - learning_rate: 1.0000e-03\n",
      "Epoch 6/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2243 - val_loss: 0.3182 - learning_rate: 1.0000e-03\n",
      "Epoch 7/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2092 - val_loss: 0.3114 - learning_rate: 1.0000e-03\n",
      "Epoch 8/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1962 - val_loss: 0.3123 - learning_rate: 1.0000e-03\n",
      "Epoch 9/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1872 - val_loss: 0.2988 - learning_rate: 1.0000e-03\n",
      "Epoch 10/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1774 - val_loss: 0.2865 - learning_rate: 1.0000e-03\n",
      "Epoch 11/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1728 - val_loss: 0.2753 - learning_rate: 1.0000e-03\n",
      "Epoch 12/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1640 - val_loss: 0.2474 - learning_rate: 1.0000e-03\n",
      "Epoch 13/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1609 - val_loss: 0.2792 - learning_rate: 1.0000e-03\n",
      "Epoch 14/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1542 - val_loss: 0.3073 - learning_rate: 1.0000e-03\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1522 - val_loss: 0.3175 - learning_rate: 1.0000e-03\n",
      "Epoch 16/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1428 - val_loss: 0.2947 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1427 - val_loss: 0.3334 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1403 - val_loss: 0.2945 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1404 - val_loss: 0.2717 - learning_rate: 6.2500e-05\n",
      "Epoch 20/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1380 - val_loss: 0.2725 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1382 - val_loss: 0.2714 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1373 - val_loss: 0.2764 - learning_rate: 1.5625e-05\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m2373/2373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250us/step\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step\n",
      "Iteration 3 complete\n",
      "Epoch 1/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 1.0721 - val_loss: 0.7695 - learning_rate: 1.0000e-03\n",
      "Epoch 2/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.4564 - val_loss: 0.5269 - learning_rate: 1.0000e-03\n",
      "Epoch 3/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.3300 - val_loss: 0.3987 - learning_rate: 1.0000e-03\n",
      "Epoch 4/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2700 - val_loss: 0.3544 - learning_rate: 1.0000e-03\n",
      "Epoch 5/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2426 - val_loss: 0.3577 - learning_rate: 1.0000e-03\n",
      "Epoch 6/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2232 - val_loss: 0.3157 - learning_rate: 1.0000e-03\n",
      "Epoch 7/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2087 - val_loss: 0.2464 - learning_rate: 1.0000e-03\n",
      "Epoch 8/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1954 - val_loss: 0.2822 - learning_rate: 1.0000e-03\n",
      "Epoch 9/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1861 - val_loss: 0.2787 - learning_rate: 1.0000e-03\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1796 - val_loss: 0.2633 - learning_rate: 1.0000e-03\n",
      "Epoch 11/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1667 - val_loss: 0.2703 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1658 - val_loss: 0.2774 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1648 - val_loss: 0.2711 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1597 - val_loss: 0.2864 - learning_rate: 6.2500e-05\n",
      "Epoch 15/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1593 - val_loss: 0.2954 - learning_rate: 6.2500e-05\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1593 - val_loss: 0.2480 - learning_rate: 6.2500e-05\n",
      "Epoch 17/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1590 - val_loss: 0.2851 - learning_rate: 1.5625e-05\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m2373/2373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 247us/step\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step\n",
      "Iteration 4 complete\n",
      "Epoch 1/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 1.0853 - val_loss: 0.6675 - learning_rate: 1.0000e-03\n",
      "Epoch 2/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.4127 - val_loss: 0.3862 - learning_rate: 1.0000e-03\n",
      "Epoch 3/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.3144 - val_loss: 0.3521 - learning_rate: 1.0000e-03\n",
      "Epoch 4/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2658 - val_loss: 0.2898 - learning_rate: 1.0000e-03\n",
      "Epoch 5/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2412 - val_loss: 0.2904 - learning_rate: 1.0000e-03\n",
      "Epoch 6/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2222 - val_loss: 0.2779 - learning_rate: 1.0000e-03\n",
      "Epoch 7/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.2092 - val_loss: 0.3026 - learning_rate: 1.0000e-03\n",
      "Epoch 8/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1976 - val_loss: 0.3193 - learning_rate: 1.0000e-03\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1897 - val_loss: 0.2983 - learning_rate: 1.0000e-03\n",
      "Epoch 10/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1773 - val_loss: 0.2908 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1733 - val_loss: 0.2945 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1727 - val_loss: 0.2591 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1704 - val_loss: 0.2850 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1694 - val_loss: 0.2718 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1664 - val_loss: 0.2716 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1650 - val_loss: 0.2656 - learning_rate: 6.2500e-05\n",
      "Epoch 17/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1639 - val_loss: 0.2686 - learning_rate: 6.2500e-05\n",
      "Epoch 18/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1658 - val_loss: 0.2540 - learning_rate: 6.2500e-05\n",
      "Epoch 19/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1624 - val_loss: 0.2690 - learning_rate: 6.2500e-05\n",
      "Epoch 20/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1631 - val_loss: 0.2673 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1638 - val_loss: 0.2687 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1637 - val_loss: 0.2651 - learning_rate: 1.5625e-05\n",
      "Epoch 23/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1625 - val_loss: 0.2863 - learning_rate: 1.5625e-05\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1631 - val_loss: 0.2574 - learning_rate: 1.5625e-05\n",
      "Epoch 25/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1615 - val_loss: 0.2532 - learning_rate: 3.9063e-06\n",
      "Epoch 26/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1628 - val_loss: 0.2723 - learning_rate: 3.9063e-06\n",
      "Epoch 27/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1618 - val_loss: 0.2558 - learning_rate: 3.9063e-06\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1607 - val_loss: 0.2713 - learning_rate: 3.9063e-06\n",
      "Epoch 29/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1610 - val_loss: 0.2656 - learning_rate: 9.7656e-07\n",
      "Epoch 30/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1631 - val_loss: 0.2631 - learning_rate: 9.7656e-07\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1611 - val_loss: 0.2629 - learning_rate: 9.7656e-07\n",
      "Epoch 32/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1605 - val_loss: 0.2624 - learning_rate: 2.4414e-07\n",
      "Epoch 33/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1618 - val_loss: 0.2669 - learning_rate: 2.4414e-07\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1630 - val_loss: 0.2760 - learning_rate: 2.4414e-07\n",
      "Epoch 35/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 0.1616 - val_loss: 0.2648 - learning_rate: 6.1035e-08\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "\u001b[1m2373/2373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253us/step\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step\n",
      "Iteration 5 complete\n"
     ]
    }
   ],
   "source": [
    "# run all country model\n",
    "for i in range(1,6):\n",
    "    # Set reproducible seeds per iteration\n",
    "    np.random.seed(i)\n",
    "    tf.random.set_seed(i)\n",
    "    random.seed(i)\n",
    "    os.environ['PYTHONHASHSEED'] = str(i)\n",
    "\n",
    "    model_country, loss_info_country = training_functions.run_deep_model(train_prepped, test_prepped, country_geo_dim, \n",
    "                                                                         epochs=50, \n",
    "                                                                         steps_per_epoch=1405, \n",
    "                                                                         lograte=True)\n",
    "\n",
    "    training_input_features = (tf.convert_to_tensor((asfr_training[:,1] - 1950) / (2015-1950), dtype=tf.float32),  # Normalized year\n",
    "                            tf.convert_to_tensor(asfr_training[:,2], dtype=tf.float32),  # Age\n",
    "                            tf.convert_to_tensor(asfr_training[:,0], dtype=tf.float32))  # Geo\n",
    "    \n",
    "    test_input_features = (tf.convert_to_tensor((asfr_test[:,1] - 1950) / (2015-1950), dtype=tf.float32),  # Normalized year\n",
    "                        tf.convert_to_tensor(asfr_test[:,2], dtype=tf.float32),  # Age\n",
    "                        tf.convert_to_tensor(asfr_test[:,0], dtype=tf.float32))  # Geo\n",
    "\n",
    "    training_predictions = model_country.predict(training_input_features)\n",
    "\n",
    "    test_predictions = model_country.predict(test_input_features)\n",
    "\n",
    "    inputs = np.delete(asfr_training, 3, axis=1)\n",
    "    training_predictions = np.column_stack((inputs, training_predictions))\n",
    "    inputs_test = np.delete(asfr_test, 3, axis=1)\n",
    "    test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "    model_country.save(f\"../models/dl_model_{i}.keras\")\n",
    "\n",
    "    np.savetxt(f\"../data/dl_fitted_{i}.txt\", training_predictions)\n",
    "    np.savetxt(f\"../data/dl_forecast_{i}.txt\", test_predictions)    \n",
    "\n",
    "    print(f\"Iteration {i} complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non-log model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "train_prepped = training_functions.prep_data(asfr_training, mode=\"train\", changeratetolog=False)\n",
    "test_prepped = training_functions.prep_data(asfr_test, mode=\"test\", changeratetolog=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 0.0015 - val_loss: 6.8497e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 2/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 4.8703e-04 - val_loss: 5.8749e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 3/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 2.6083e-04 - val_loss: 2.3624e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 4/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 1.7099e-04 - val_loss: 1.7458e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 5/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 1.3381e-04 - val_loss: 1.4241e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 6/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 1.1481e-04 - val_loss: 1.5055e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 7/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 9.8164e-05 - val_loss: 1.5354e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 8/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 8.4813e-05 - val_loss: 1.2964e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 9/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 7.4455e-05 - val_loss: 1.2589e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 10/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 6.6200e-05 - val_loss: 1.2007e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 11/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 6.0163e-05 - val_loss: 1.1557e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 12/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 5.4690e-05 - val_loss: 1.1671e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 13/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 5.0379e-05 - val_loss: 1.1009e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 14/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 4.7159e-05 - val_loss: 8.5635e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 15/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 4.3985e-05 - val_loss: 1.0039e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 16/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 4.1579e-05 - val_loss: 1.0590e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1405/1405 - 3s - 2ms/step - loss: 3.9558e-05 - val_loss: 9.8304e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 18/50\n",
      "1405/1405 - 3s - 2ms/step - loss: 3.4689e-05 - val_loss: 9.8448e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 3.3902e-05 - val_loss: 9.5518e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1405/1405 - 3s - 2ms/step - loss: 3.3239e-05 - val_loss: 9.7750e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 3.2285e-05 - val_loss: 9.2518e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "1405/1405 - 4s - 2ms/step - loss: 3.1793e-05 - val_loss: 9.6893e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1405/1405 - 4s - 3ms/step - loss: 3.1696e-05 - val_loss: 9.2704e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 3.1608e-05 - val_loss: 9.6057e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m2373/2373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237us/step\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step\n"
     ]
    }
   ],
   "source": [
    "model_country, loss_info_country = training_functions.run_deep_model(train_prepped, test_prepped, country_geo_dim, \n",
    "                                                                        epochs=50, \n",
    "                                                                        steps_per_epoch=1405, \n",
    "                                                                        lograte=False)\n",
    "\n",
    "training_input_features = (tf.convert_to_tensor((asfr_training[:,1] - 1950) / (2015-1950), dtype=tf.float32),  # Normalized year\n",
    "                        tf.convert_to_tensor(asfr_training[:,2], dtype=tf.float32),  # Age\n",
    "                        tf.convert_to_tensor(asfr_training[:,0], dtype=tf.float32))  # Geo\n",
    "\n",
    "test_input_features = (tf.convert_to_tensor((asfr_test[:,1] - 1950) / (2015-1950), dtype=tf.float32),  # Normalized year\n",
    "                    tf.convert_to_tensor(asfr_test[:,2], dtype=tf.float32),  # Age\n",
    "                    tf.convert_to_tensor(asfr_test[:,0], dtype=tf.float32))  # Geo\n",
    "\n",
    "training_predictions = model_country.predict(training_input_features)\n",
    "\n",
    "test_predictions = model_country.predict(test_input_features)\n",
    "\n",
    "inputs = np.delete(asfr_training, 3, axis=1)\n",
    "training_predictions = np.column_stack((inputs, training_predictions))\n",
    "inputs_test = np.delete(asfr_test, 3, axis=1)\n",
    "test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "np.savetxt(f\"../data/dl_fitted_nonlog.txt\", training_predictions)\n",
    "np.savetxt(f\"../data/dl_forecast_nonlog.txt\", test_predictions)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-fert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
