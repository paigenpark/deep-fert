{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Cohort Fertility Prediction\n",
    "\n",
    "Trains the non-log DL model with rotating jump-off years (1985-2010) and converts predictions to cohort rates for comparison with the Lee (1993) benchmark.\n",
    "\n",
    "Aligned with R Lee-Carter approach:\n",
    "- Ages 15-44 (matching `age1=15, age2=44`)\n",
    "- Country filtering: skips countries missing any age in 15-44\n",
    "- Year gap checks: skips country/JOY combos with gaps in observed years\n",
    "- Forecast horizon: JOY + 30 years (matching `len=30`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_functions' from '/Users/paigepark/Desktop/repos/deep-fert/code/training_functions.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import training_functions\n",
    "import importlib\n",
    "\n",
    "importlib.reload(training_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: (92190, 4)\n",
      "Filtered (ages 15-44): (65850, 4)\n",
      "Years: 1950-2015\n",
      "Ages: 15-44\n",
      "Countries: 39\n"
     ]
    }
   ],
   "source": [
    "asfr_training = np.loadtxt('../data/asfr_training.txt')\n",
    "asfr_test = np.loadtxt('../data/asfr_test.txt')\n",
    "asfr_all_raw = np.vstack([asfr_training, asfr_test])\n",
    "\n",
    "# Save unfiltered data for R scripts\n",
    "np.savetxt('../data/asfr_1950_to_2015.txt', asfr_all_raw)\n",
    "\n",
    "# Filter to ages 15-44 to match R's Lee-Carter approach (age1=15, age2=44)\n",
    "AGE_MIN = 15\n",
    "AGE_MAX = 44\n",
    "age_mask = (asfr_all_raw[:, 2] >= AGE_MIN) & (asfr_all_raw[:, 2] <= AGE_MAX)\n",
    "asfr_all = asfr_all_raw[age_mask]\n",
    "\n",
    "print(f\"Raw: {asfr_all_raw.shape}\")\n",
    "print(f\"Filtered (ages {AGE_MIN}-{AGE_MAX}): {asfr_all.shape}\")\n",
    "print(f\"Years: {int(asfr_all[:,1].min())}-{int(asfr_all[:,1].max())}\")\n",
    "print(f\"Ages: {int(asfr_all[:,2].min())}-{int(asfr_all[:,2].max())}\")\n",
    "print(f\"Countries: {int(asfr_all[:,0].max()) + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOY 1985: 36 valid countries\n",
      "JOY 1990: 36 valid countries\n",
      "JOY 1995: 37 valid countries\n",
      "JOY 2000: 38 valid countries\n",
      "JOY 2005: 39 valid countries\n",
      "JOY 2010: 39 valid countries\n",
      "\n",
      "geo_dim: 39\n",
      "Valid countries: 39\n",
      "Jump-off years: [1985, 1990, 1995, 2000, 2005, 2010]\n"
     ]
    }
   ],
   "source": [
    "JUMP_OFF_YEARS = [1985, 1990, 1995, 2000, 2005, 2010]\n",
    "YEAR_MIN = 1950\n",
    "YEAR_MAX = 2015\n",
    "FORECAST_LEN = 30  # Match R's len=30\n",
    "STEPS_RATIO = 4.74\n",
    "BATCH_SIZE = 256\n",
    "METHOD_NAME = \"DL_NonLog\"\n",
    "\n",
    "geo_dim = int(asfr_all[:, 0].max()) + 1\n",
    "ages = np.arange(AGE_MIN, AGE_MAX + 1)\n",
    "countries = np.arange(geo_dim)\n",
    "\n",
    "# Country validation: skip countries missing any age in 15-44 (matching R)\n",
    "required_ages = set(range(AGE_MIN, AGE_MAX + 1))\n",
    "valid_countries = []\n",
    "country_min_year = {}\n",
    "\n",
    "for c in countries:\n",
    "    c_data = asfr_all[asfr_all[:, 0] == c]\n",
    "    if len(c_data) == 0:\n",
    "        continue\n",
    "    c_ages = set(c_data[:, 2].astype(int))\n",
    "    missing = required_ages - c_ages\n",
    "    if missing:\n",
    "        print(f\"Skipping Country {int(c)} - Missing ages: {sorted(missing)}\")\n",
    "        continue\n",
    "    valid_countries.append(int(c))\n",
    "    country_min_year[int(c)] = int(c_data[:, 1].min())\n",
    "\n",
    "# For each JOY, check for year gaps per country (matching R)\n",
    "valid_combos = {}  # joy -> list of valid country indices\n",
    "for joy in JUMP_OFF_YEARS:\n",
    "    valid_for_joy = []\n",
    "    for c in valid_countries:\n",
    "        min_yr = country_min_year[c]\n",
    "        if joy > YEAR_MAX or joy < min_yr:\n",
    "            continue\n",
    "        # Check all years from min_data_year to joy are present\n",
    "        c_data = asfr_all[asfr_all[:, 0] == c]\n",
    "        available_years = set(c_data[:, 1].astype(int))\n",
    "        required_years = set(range(min_yr, joy + 1))\n",
    "        missing_years = required_years - available_years\n",
    "        if missing_years:\n",
    "            print(f\"Skipping Country {c}, JOY {joy} - Missing years: {sorted(missing_years)[:5]}\")\n",
    "            continue\n",
    "        valid_for_joy.append(c)\n",
    "    valid_combos[joy] = valid_for_joy\n",
    "    print(f\"JOY {joy}: {len(valid_for_joy)} valid countries\")\n",
    "\n",
    "print(f\"\\ngeo_dim: {geo_dim}\")\n",
    "print(f\"Valid countries: {len(valid_countries)}\")\n",
    "print(f\"Jump-off years: {JUMP_OFF_YEARS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Jump-off year: 1985\n",
      "==================================================\n",
      "Training rows: 31890\n",
      "Validation rows: 33960\n",
      "Steps per epoch: 590\n",
      "Epoch 1/50\n",
      "590/590 - 3s - 5ms/step - loss: 0.0031 - val_loss: 9.6536e-04 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "590/590 - 2s - 3ms/step - loss: 8.4234e-04 - val_loss: 0.0011 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "590/590 - 2s - 3ms/step - loss: 6.3136e-04 - val_loss: 0.0012 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "590/590 - 2s - 3ms/step - loss: 4.2410e-04 - val_loss: 0.0011 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "590/590 - 1s - 3ms/step - loss: 3.5307e-04 - val_loss: 0.0010 - learning_rate: 2.5000e-04\n",
      "Epoch 6/50\n",
      "590/590 - 1s - 3ms/step - loss: 3.2680e-04 - val_loss: 0.0010 - learning_rate: 2.5000e-04\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "590/590 - 1s - 3ms/step - loss: 3.0278e-04 - val_loss: 9.9931e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 8/50\n",
      "590/590 - 1s - 3ms/step - loss: 2.9098e-04 - val_loss: 0.0010 - learning_rate: 6.2500e-05\n",
      "Epoch 9/50\n",
      "590/590 - 1s - 2ms/step - loss: 2.8540e-04 - val_loss: 9.9542e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "590/590 - 1s - 3ms/step - loss: 2.7778e-04 - val_loss: 9.9320e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 11/50\n",
      "590/590 - 2s - 3ms/step - loss: 2.6918e-04 - val_loss: 9.9870e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Best val loss: 0.000965\n",
      "Forecast grid: 32400 (36 countries, 30 years, 30 ages)\n",
      "\u001b[1m1013/1013\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step\n",
      "Model saved: ../models/dl_cohort_nonlog_joy1985.keras\n",
      "\n",
      "==================================================\n",
      "Jump-off year: 1990\n",
      "==================================================\n",
      "Training rows: 37290\n",
      "Validation rows: 28560\n",
      "Steps per epoch: 690\n",
      "Epoch 1/50\n",
      "690/690 - 3s - 4ms/step - loss: 0.0029 - val_loss: 0.0011 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "690/690 - 2s - 3ms/step - loss: 8.0836e-04 - val_loss: 0.0011 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "690/690 - 2s - 3ms/step - loss: 6.2366e-04 - val_loss: 0.0011 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "690/690 - 2s - 3ms/step - loss: 4.1976e-04 - val_loss: 8.8868e-04 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "690/690 - 2s - 3ms/step - loss: 3.2376e-04 - val_loss: 7.7117e-04 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "690/690 - 2s - 3ms/step - loss: 2.5602e-04 - val_loss: 7.5498e-04 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "690/690 - 2s - 3ms/step - loss: 2.1251e-04 - val_loss: 6.7284e-04 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "690/690 - 2s - 3ms/step - loss: 1.8314e-04 - val_loss: 6.2718e-04 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "690/690 - 2s - 3ms/step - loss: 1.6080e-04 - val_loss: 5.7702e-04 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "690/690 - 2s - 3ms/step - loss: 1.4502e-04 - val_loss: 5.3811e-04 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "690/690 - 2s - 3ms/step - loss: 1.3089e-04 - val_loss: 4.8067e-04 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "690/690 - 2s - 3ms/step - loss: 1.2313e-04 - val_loss: 5.1142e-04 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "690/690 - 2s - 3ms/step - loss: 1.0935e-04 - val_loss: 4.5494e-04 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "690/690 - 2s - 3ms/step - loss: 1.0101e-04 - val_loss: 4.4493e-04 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "690/690 - 2s - 3ms/step - loss: 9.3450e-05 - val_loss: 4.2936e-04 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "690/690 - 2s - 3ms/step - loss: 8.6871e-05 - val_loss: 3.9692e-04 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "690/690 - 2s - 3ms/step - loss: 8.0888e-05 - val_loss: 3.8359e-04 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "690/690 - 2s - 3ms/step - loss: 7.6801e-05 - val_loss: 3.7210e-04 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "690/690 - 2s - 3ms/step - loss: 7.3177e-05 - val_loss: 3.7031e-04 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "690/690 - 2s - 3ms/step - loss: 6.9538e-05 - val_loss: 3.6866e-04 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "690/690 - 2s - 3ms/step - loss: 6.5349e-05 - val_loss: 3.8978e-04 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "690/690 - 2s - 4ms/step - loss: 6.1831e-05 - val_loss: 3.5677e-04 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "690/690 - 2s - 3ms/step - loss: 5.9792e-05 - val_loss: 3.5409e-04 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "690/690 - 2s - 3ms/step - loss: 5.7463e-05 - val_loss: 3.8428e-04 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "690/690 - 2s - 3ms/step - loss: 5.5005e-05 - val_loss: 4.0423e-04 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "690/690 - 2s - 3ms/step - loss: 5.3208e-05 - val_loss: 3.8754e-04 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "690/690 - 2s - 3ms/step - loss: 4.7874e-05 - val_loss: 3.9585e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "690/690 - 2s - 3ms/step - loss: 4.6985e-05 - val_loss: 4.0081e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "690/690 - 2s - 3ms/step - loss: 4.6727e-05 - val_loss: 3.9418e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "690/690 - 2s - 3ms/step - loss: 4.5400e-05 - val_loss: 3.9770e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "690/690 - 2s - 3ms/step - loss: 4.4645e-05 - val_loss: 4.0761e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "690/690 - 2s - 3ms/step - loss: 4.4763e-05 - val_loss: 4.1599e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "690/690 - 2s - 3ms/step - loss: 4.4315e-05 - val_loss: 4.1589e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Best val loss: 0.000354\n",
      "Forecast grid: 32400 (36 countries, 30 years, 30 ages)\n",
      "\u001b[1m1013/1013\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step\n",
      "Model saved: ../models/dl_cohort_nonlog_joy1990.keras\n",
      "\n",
      "==================================================\n",
      "Jump-off year: 1995\n",
      "==================================================\n",
      "Training rows: 42810\n",
      "Validation rows: 23040\n",
      "Steps per epoch: 792\n",
      "Epoch 1/50\n",
      "792/792 - 3s - 4ms/step - loss: 0.0026 - val_loss: 9.5190e-04 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "792/792 - 2s - 3ms/step - loss: 7.6942e-04 - val_loss: 9.1777e-04 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "792/792 - 2s - 3ms/step - loss: 4.8174e-04 - val_loss: 8.1436e-04 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "792/792 - 2s - 3ms/step - loss: 3.4757e-04 - val_loss: 6.8967e-04 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "792/792 - 2s - 3ms/step - loss: 2.8154e-04 - val_loss: 6.1103e-04 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "792/792 - 2s - 3ms/step - loss: 2.3235e-04 - val_loss: 5.0044e-04 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "792/792 - 2s - 3ms/step - loss: 1.9690e-04 - val_loss: 3.8415e-04 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "792/792 - 2s - 3ms/step - loss: 1.6820e-04 - val_loss: 3.2614e-04 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "792/792 - 2s - 3ms/step - loss: 1.5062e-04 - val_loss: 2.7927e-04 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "792/792 - 2s - 3ms/step - loss: 1.3388e-04 - val_loss: 2.8483e-04 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "792/792 - 2s - 3ms/step - loss: 1.2100e-04 - val_loss: 2.7393e-04 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "792/792 - 2s - 3ms/step - loss: 1.1162e-04 - val_loss: 2.8422e-04 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "792/792 - 2s - 3ms/step - loss: 1.0173e-04 - val_loss: 2.7027e-04 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "792/792 - 2s - 3ms/step - loss: 9.4792e-05 - val_loss: 2.8949e-04 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "792/792 - 2s - 3ms/step - loss: 8.7627e-05 - val_loss: 3.0324e-04 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "792/792 - 2s - 3ms/step - loss: 8.2502e-05 - val_loss: 2.9982e-04 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "792/792 - 2s - 3ms/step - loss: 7.3309e-05 - val_loss: 2.9513e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "792/792 - 2s - 3ms/step - loss: 7.2456e-05 - val_loss: 2.8348e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "792/792 - 2s - 3ms/step - loss: 7.0756e-05 - val_loss: 2.9389e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "792/792 - 2s - 3ms/step - loss: 6.9268e-05 - val_loss: 2.8791e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "792/792 - 2s - 3ms/step - loss: 6.8010e-05 - val_loss: 2.9717e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "792/792 - 2s - 3ms/step - loss: 6.7635e-05 - val_loss: 2.9315e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "792/792 - 2s - 3ms/step - loss: 6.6903e-05 - val_loss: 2.9839e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Best val loss: 0.000270\n",
      "Forecast grid: 33300 (37 countries, 30 years, 30 ages)\n",
      "\u001b[1m1041/1041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step\n",
      "Model saved: ../models/dl_cohort_nonlog_joy1995.keras\n",
      "\n",
      "==================================================\n",
      "Jump-off year: 2000\n",
      "==================================================\n",
      "Training rows: 48390\n",
      "Validation rows: 17460\n",
      "Steps per epoch: 895\n",
      "Epoch 1/50\n",
      "895/895 - 4s - 4ms/step - loss: 0.0023 - val_loss: 8.9861e-04 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "895/895 - 2s - 3ms/step - loss: 7.6298e-04 - val_loss: 8.6910e-04 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "895/895 - 2s - 3ms/step - loss: 4.7815e-04 - val_loss: 6.4559e-04 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "895/895 - 2s - 3ms/step - loss: 3.1846e-04 - val_loss: 5.1616e-04 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "895/895 - 3s - 3ms/step - loss: 2.4982e-04 - val_loss: 3.5513e-04 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "895/895 - 3s - 3ms/step - loss: 2.0166e-04 - val_loss: 3.0585e-04 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "895/895 - 3s - 3ms/step - loss: 1.6926e-04 - val_loss: 2.4393e-04 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "895/895 - 3s - 3ms/step - loss: 1.4783e-04 - val_loss: 2.6143e-04 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "895/895 - 3s - 3ms/step - loss: 1.3052e-04 - val_loss: 2.2671e-04 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "895/895 - 3s - 3ms/step - loss: 1.1692e-04 - val_loss: 2.4190e-04 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "895/895 - 3s - 3ms/step - loss: 1.0662e-04 - val_loss: 2.3651e-04 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "895/895 - 3s - 3ms/step - loss: 9.7387e-05 - val_loss: 2.1902e-04 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "895/895 - 3s - 3ms/step - loss: 8.8320e-05 - val_loss: 2.0810e-04 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "895/895 - 2s - 3ms/step - loss: 8.2210e-05 - val_loss: 2.1093e-04 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "895/895 - 2s - 3ms/step - loss: 7.7260e-05 - val_loss: 2.1655e-04 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "895/895 - 2s - 3ms/step - loss: 7.2302e-05 - val_loss: 2.1099e-04 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "895/895 - 2s - 3ms/step - loss: 6.3294e-05 - val_loss: 2.0991e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "895/895 - 2s - 3ms/step - loss: 6.2168e-05 - val_loss: 2.1380e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "895/895 - 2s - 3ms/step - loss: 6.1099e-05 - val_loss: 2.0372e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "895/895 - 2s - 3ms/step - loss: 5.9677e-05 - val_loss: 2.1815e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "895/895 - 2s - 3ms/step - loss: 5.8463e-05 - val_loss: 2.0068e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "895/895 - 2s - 3ms/step - loss: 5.7421e-05 - val_loss: 2.1562e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "895/895 - 2s - 3ms/step - loss: 5.6336e-05 - val_loss: 2.0855e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "895/895 - 2s - 3ms/step - loss: 5.5026e-05 - val_loss: 2.0164e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "895/895 - 2s - 3ms/step - loss: 5.3549e-05 - val_loss: 2.0374e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "895/895 - 2s - 3ms/step - loss: 5.3428e-05 - val_loss: 2.0240e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "895/895 - 2s - 3ms/step - loss: 5.3249e-05 - val_loss: 2.0036e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "895/895 - 2s - 3ms/step - loss: 5.2706e-05 - val_loss: 2.0792e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "895/895 - 3s - 3ms/step - loss: 5.2436e-05 - val_loss: 2.0501e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "895/895 - 2s - 3ms/step - loss: 5.2084e-05 - val_loss: 1.9983e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "895/895 - 2s - 3ms/step - loss: 5.1582e-05 - val_loss: 2.0472e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "895/895 - 3s - 3ms/step - loss: 5.1832e-05 - val_loss: 2.0398e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "895/895 - 3s - 3ms/step - loss: 5.1209e-05 - val_loss: 1.9715e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 34/50\n",
      "895/895 - 3s - 3ms/step - loss: 5.1250e-05 - val_loss: 2.0323e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 35/50\n",
      "895/895 - 3s - 3ms/step - loss: 5.0856e-05 - val_loss: 2.0015e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "895/895 - 3s - 3ms/step - loss: 5.0622e-05 - val_loss: 2.0402e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 37/50\n",
      "895/895 - 3s - 3ms/step - loss: 5.0334e-05 - val_loss: 2.0086e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 38/50\n",
      "895/895 - 3s - 3ms/step - loss: 5.0294e-05 - val_loss: 2.0251e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "895/895 - 3s - 3ms/step - loss: 5.0735e-05 - val_loss: 2.0195e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 40/50\n",
      "895/895 - 3s - 3ms/step - loss: 4.9949e-05 - val_loss: 2.0087e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 41/50\n",
      "895/895 - 3s - 3ms/step - loss: 4.9889e-05 - val_loss: 2.0467e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "895/895 - 3s - 3ms/step - loss: 4.9926e-05 - val_loss: 2.0345e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 43/50\n",
      "895/895 - 3s - 3ms/step - loss: 5.0087e-05 - val_loss: 2.0204e-04 - learning_rate: 9.7656e-07\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Best val loss: 0.000197\n",
      "Forecast grid: 34200 (38 countries, 30 years, 30 ages)\n",
      "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step\n",
      "Model saved: ../models/dl_cohort_nonlog_joy2000.keras\n",
      "\n",
      "==================================================\n",
      "Jump-off year: 2005\n",
      "==================================================\n",
      "Training rows: 54240\n",
      "Validation rows: 11610\n",
      "Steps per epoch: 1004\n",
      "Epoch 1/50\n",
      "1004/1004 - 4s - 4ms/step - loss: 0.0021 - val_loss: 9.2702e-04 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 7.4084e-04 - val_loss: 8.5470e-04 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 4.3952e-04 - val_loss: 5.0799e-04 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 2.9307e-04 - val_loss: 3.7662e-04 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 2.2284e-04 - val_loss: 2.5804e-04 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 1.7977e-04 - val_loss: 2.4984e-04 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 1.5429e-04 - val_loss: 2.1520e-04 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 1.3354e-04 - val_loss: 1.7775e-04 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 1.1935e-04 - val_loss: 1.7549e-04 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 1.0632e-04 - val_loss: 1.9718e-04 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 9.6895e-05 - val_loss: 1.9033e-04 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1004/1004 - 3s - 3ms/step - loss: 8.8895e-05 - val_loss: 1.7559e-04 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 7.9646e-05 - val_loss: 1.6189e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 7.7382e-05 - val_loss: 1.7028e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 7.5718e-05 - val_loss: 1.4342e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 7.3199e-05 - val_loss: 1.8091e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 7.2458e-05 - val_loss: 1.5981e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1004/1004 - 3s - 3ms/step - loss: 7.0673e-05 - val_loss: 1.4944e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 6.8513e-05 - val_loss: 1.5087e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 20/50\n",
      "1004/1004 - 4s - 4ms/step - loss: 6.7388e-05 - val_loss: 1.5156e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 6.7223e-05 - val_loss: 1.4127e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 6.6535e-05 - val_loss: 1.4883e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "1004/1004 - 4s - 4ms/step - loss: 6.6396e-05 - val_loss: 1.5627e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1004/1004 - 3s - 3ms/step - loss: 6.5694e-05 - val_loss: 1.4489e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 6.5557e-05 - val_loss: 1.5613e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 26/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 6.5240e-05 - val_loss: 1.5067e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "1004/1004 - 4s - 4ms/step - loss: 6.4971e-05 - val_loss: 1.5037e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 28/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 6.5089e-05 - val_loss: 1.5059e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 29/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 6.4923e-05 - val_loss: 1.4812e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "1004/1004 - 3s - 3ms/step - loss: 6.4904e-05 - val_loss: 1.4949e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 31/50\n",
      "1004/1004 - 3s - 3ms/step - loss: 6.5068e-05 - val_loss: 1.4854e-04 - learning_rate: 9.7656e-07\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Best val loss: 0.000141\n",
      "Forecast grid: 35100 (39 countries, 30 years, 30 ages)\n",
      "\u001b[1m1097/1097\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step\n",
      "Model saved: ../models/dl_cohort_nonlog_joy2005.keras\n",
      "\n",
      "==================================================\n",
      "Jump-off year: 2010\n",
      "==================================================\n",
      "Training rows: 60090\n",
      "Validation rows: 5760\n",
      "Steps per epoch: 1112\n",
      "Epoch 1/50\n",
      "1112/1112 - 4s - 4ms/step - loss: 0.0019 - val_loss: 8.9515e-04 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 6.6830e-04 - val_loss: 6.4189e-04 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 3.4981e-04 - val_loss: 2.5821e-04 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 2.4416e-04 - val_loss: 1.5910e-04 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 1.9701e-04 - val_loss: 1.5160e-04 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 1.6765e-04 - val_loss: 1.1768e-04 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 1.4364e-04 - val_loss: 1.1420e-04 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 1.2568e-04 - val_loss: 8.4061e-05 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 1.1080e-04 - val_loss: 7.5296e-05 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 9.9294e-05 - val_loss: 7.1929e-05 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 9.0122e-05 - val_loss: 6.7279e-05 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 8.2423e-05 - val_loss: 6.7050e-05 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 7.6269e-05 - val_loss: 5.9112e-05 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 7.0390e-05 - val_loss: 6.1862e-05 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 6.7098e-05 - val_loss: 6.3527e-05 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 6.3004e-05 - val_loss: 5.5016e-05 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 5.8964e-05 - val_loss: 5.4037e-05 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 5.6855e-05 - val_loss: 5.4843e-05 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 5.4227e-05 - val_loss: 5.8018e-05 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1112/1112 - 3s - 3ms/step - loss: 5.1684e-05 - val_loss: 5.6426e-05 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 4.6769e-05 - val_loss: 5.5777e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 4.5818e-05 - val_loss: 4.9241e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 4.5607e-05 - val_loss: 4.7665e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 4.5153e-05 - val_loss: 5.0466e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 4.4855e-05 - val_loss: 5.3744e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1112/1112 - 3s - 3ms/step - loss: 4.4153e-05 - val_loss: 5.3324e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 4.3078e-05 - val_loss: 5.1410e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 4.2711e-05 - val_loss: 5.0249e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1112/1112 - 3s - 3ms/step - loss: 4.2662e-05 - val_loss: 5.1555e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 4.2099e-05 - val_loss: 5.1445e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 31/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 4.1967e-05 - val_loss: 5.0445e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "1112/1112 - 3s - 3ms/step - loss: 4.2111e-05 - val_loss: 5.1341e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 33/50\n",
      "1112/1112 - 3s - 3ms/step - loss: 4.2204e-05 - val_loss: 5.1354e-05 - learning_rate: 3.9063e-06\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Best val loss: 0.000048\n",
      "Forecast grid: 35100 (39 countries, 30 years, 30 ages)\n",
      "\u001b[1m1097/1097\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step\n",
      "Model saved: ../models/dl_cohort_nonlog_joy2010.keras\n",
      "\n",
      "All jump-off years complete!\n"
     ]
    }
   ],
   "source": [
    "predicted_rates = {}\n",
    "observed_rates = {}\n",
    "\n",
    "for joy in JUMP_OFF_YEARS:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Jump-off year: {joy}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # 1. Training data: all valid countries, ages 15-44, year <= joy\n",
    "    train_mask = (asfr_all[:, 1] <= joy) & np.isin(asfr_all[:, 0].astype(int), valid_countries)\n",
    "    train_data = asfr_all[train_mask]\n",
    "    print(f\"Training rows: {train_data.shape[0]}\")\n",
    "\n",
    "    # 2. Validation data: valid countries, year > joy (up to YEAR_MAX)\n",
    "    val_mask = (asfr_all[:, 1] > joy) & np.isin(asfr_all[:, 0].astype(int), valid_countries)\n",
    "    val_data = asfr_all[val_mask]\n",
    "    print(f\"Validation rows: {val_data.shape[0]}\")\n",
    "\n",
    "    if train_data.shape[0] == 0:\n",
    "        print(\"No training data, skipping\")\n",
    "        continue\n",
    "\n",
    "    # 3. Scale steps_per_epoch\n",
    "    steps_per_epoch = int(train_data.shape[0] * STEPS_RATIO / BATCH_SIZE)\n",
    "    print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "\n",
    "    # 4. Prep datasets\n",
    "    train_prepped = training_functions.prep_data(train_data, mode=\"train\", changeratetolog=False)\n",
    "    val_prepped = training_functions.prep_data(val_data, mode=\"test\", changeratetolog=False)\n",
    "\n",
    "    # 5. Set seeds and train non-log model\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    random.seed(42)\n",
    "    os.environ['PYTHONHASHSEED'] = str(42)\n",
    "\n",
    "    model, val_loss = training_functions.run_deep_model(\n",
    "        train_prepped, val_prepped, geo_dim,\n",
    "        epochs=50,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        lograte=False\n",
    "    )\n",
    "    print(f\"Best val loss: {val_loss:.6f}\")\n",
    "\n",
    "    # 6. Forecast grid: valid countries for this JOY, ages 15-44, years JOY+1 to JOY+FORECAST_LEN\n",
    "    forecast_year_max = joy + FORECAST_LEN\n",
    "    forecast_years = np.arange(joy + 1, forecast_year_max + 1)\n",
    "    valid_c_list = sorted(valid_combos[joy])\n",
    "    grid = np.array([(c, y, a) for c in valid_c_list for y in forecast_years for a in ages])\n",
    "    print(f\"Forecast grid: {grid.shape[0]} ({len(valid_c_list)} countries, {len(forecast_years)} years, {len(ages)} ages)\")\n",
    "\n",
    "    # 7. Predict using same normalization as training_functions.py\n",
    "    forecast_features = (\n",
    "        tf.convert_to_tensor((grid[:, 1] - YEAR_MIN) / (YEAR_MAX - YEAR_MIN), dtype=tf.float32),\n",
    "        tf.convert_to_tensor(grid[:, 2], dtype=tf.float32),\n",
    "        tf.convert_to_tensor(grid[:, 0], dtype=tf.float32),\n",
    "    )\n",
    "    preds = model.predict(forecast_features).flatten()\n",
    "\n",
    "    # 8. Store predicted period rates\n",
    "    pred_df = pd.DataFrame({\n",
    "        'Country': grid[:, 0].astype(int),\n",
    "        'Year': grid[:, 1].astype(int),\n",
    "        'Age': grid[:, 2].astype(int),\n",
    "        'Rate': preds,\n",
    "    })\n",
    "    predicted_rates[joy] = pred_df\n",
    "\n",
    "    # 9. Store observed period rates for valid countries (year <= joy)\n",
    "    valid_c_set = set(valid_c_list)\n",
    "    obs_mask = np.isin(train_data[:, 0].astype(int), list(valid_c_set))\n",
    "    obs_data = train_data[obs_mask]\n",
    "    obs_df = pd.DataFrame({\n",
    "        'Country': obs_data[:, 0].astype(int),\n",
    "        'Year': obs_data[:, 1].astype(int),\n",
    "        'Age': obs_data[:, 2].astype(int),\n",
    "        'Rate': obs_data[:, 3],\n",
    "    })\n",
    "    observed_rates[joy] = obs_df\n",
    "\n",
    "    # 10. Save model\n",
    "    model.save(f\"../models/dl_cohort_nonlog_joy{joy}.keras\")\n",
    "    print(f\"Model saved: ../models/dl_cohort_nonlog_joy{joy}.keras\")\n",
    "\n",
    "print(\"\\nAll jump-off years complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def period_to_cohort(period_df):\n",
    "    df = period_df.copy()\n",
    "    df['Year'] = df['Year'] - df['Age']  # cohort_birth_year = period_year - age\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predCASFR shape: (477210, 7)\n",
      "Columns: ['Country', 'Year', 'Age', 'Rate', 'JumpOffYear', 'Method', 'Key']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>Rate</th>\n",
       "      <th>JumpOffYear</th>\n",
       "      <th>Method</th>\n",
       "      <th>Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1936</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>1985</td>\n",
       "      <td>DL_NonLog</td>\n",
       "      <td>DL_NonLog_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1935</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00846</td>\n",
       "      <td>1985</td>\n",
       "      <td>DL_NonLog</td>\n",
       "      <td>DL_NonLog_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1934</td>\n",
       "      <td>17</td>\n",
       "      <td>0.02615</td>\n",
       "      <td>1985</td>\n",
       "      <td>DL_NonLog</td>\n",
       "      <td>DL_NonLog_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>18</td>\n",
       "      <td>0.05113</td>\n",
       "      <td>1985</td>\n",
       "      <td>DL_NonLog</td>\n",
       "      <td>DL_NonLog_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1932</td>\n",
       "      <td>19</td>\n",
       "      <td>0.07838</td>\n",
       "      <td>1985</td>\n",
       "      <td>DL_NonLog</td>\n",
       "      <td>DL_NonLog_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  Year  Age     Rate  JumpOffYear     Method          Key\n",
       "0        0  1936   15  0.00150         1985  DL_NonLog  DL_NonLog_0\n",
       "1        0  1935   16  0.00846         1985  DL_NonLog  DL_NonLog_0\n",
       "2        0  1934   17  0.02615         1985  DL_NonLog  DL_NonLog_0\n",
       "3        0  1933   18  0.05113         1985  DL_NonLog  DL_NonLog_0\n",
       "4        0  1932   19  0.07838         1985  DL_NonLog  DL_NonLog_0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cohort_dfs = []\n",
    "\n",
    "for joy in JUMP_OFF_YEARS:\n",
    "    valid_c_set = set(valid_combos[joy])\n",
    "\n",
    "    # Observed period rates (year <= JOY), filtered to valid countries for this JOY\n",
    "    obs_period = observed_rates[joy]\n",
    "\n",
    "    # DL-predicted period rates (JOY+1 to JOY+30)\n",
    "    pred_period = predicted_rates[joy]\n",
    "\n",
    "    # Combine observed + predicted period rates\n",
    "    combined_period = pd.concat([obs_period, pred_period], ignore_index=True)\n",
    "\n",
    "    # Convert to cohort\n",
    "    cohort_df = period_to_cohort(combined_period)\n",
    "\n",
    "    # Add metadata columns\n",
    "    cohort_df['JumpOffYear'] = joy\n",
    "    cohort_df['Method'] = METHOD_NAME\n",
    "    cohort_df['Key'] = cohort_df['Method'] + '_' + cohort_df['Country'].astype(str)\n",
    "\n",
    "    pred_cohort_dfs.append(cohort_df)\n",
    "\n",
    "predCASFR = pd.concat(pred_cohort_dfs, ignore_index=True)\n",
    "print(f\"predCASFR shape: {predCASFR.shape}\")\n",
    "print(f\"Columns: {list(predCASFR.columns)}\")\n",
    "predCASFR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obsCASFR shape: (390420, 7)\n",
      "Columns: ['Country', 'Year', 'Age', 'Rate', 'JumpOffYear', 'Method', 'Key']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>Rate</th>\n",
       "      <th>JumpOffYear</th>\n",
       "      <th>Method</th>\n",
       "      <th>Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1936</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>1985</td>\n",
       "      <td>DL_NonLog</td>\n",
       "      <td>DL_NonLog_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1935</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00846</td>\n",
       "      <td>1985</td>\n",
       "      <td>DL_NonLog</td>\n",
       "      <td>DL_NonLog_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1934</td>\n",
       "      <td>17</td>\n",
       "      <td>0.02615</td>\n",
       "      <td>1985</td>\n",
       "      <td>DL_NonLog</td>\n",
       "      <td>DL_NonLog_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>18</td>\n",
       "      <td>0.05113</td>\n",
       "      <td>1985</td>\n",
       "      <td>DL_NonLog</td>\n",
       "      <td>DL_NonLog_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1932</td>\n",
       "      <td>19</td>\n",
       "      <td>0.07838</td>\n",
       "      <td>1985</td>\n",
       "      <td>DL_NonLog</td>\n",
       "      <td>DL_NonLog_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  Year  Age     Rate  JumpOffYear     Method          Key\n",
       "0        0  1936   15  0.00150         1985  DL_NonLog  DL_NonLog_0\n",
       "1        0  1935   16  0.00846         1985  DL_NonLog  DL_NonLog_0\n",
       "2        0  1934   17  0.02615         1985  DL_NonLog  DL_NonLog_0\n",
       "3        0  1933   18  0.05113         1985  DL_NonLog  DL_NonLog_0\n",
       "4        0  1932   19  0.07838         1985  DL_NonLog  DL_NonLog_0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_cohort_dfs = []\n",
    "\n",
    "# Full observed period data (ages 15-44, already filtered)\n",
    "all_obs_df = pd.DataFrame({\n",
    "    'Country': asfr_all[:, 0].astype(int),\n",
    "    'Year': asfr_all[:, 1].astype(int),\n",
    "    'Age': asfr_all[:, 2].astype(int),\n",
    "    'Rate': asfr_all[:, 3],\n",
    "})\n",
    "\n",
    "for joy in JUMP_OFF_YEARS:\n",
    "    valid_c_set = set(valid_combos[joy])\n",
    "\n",
    "    # Filter to valid countries for this JOY (matching R's per-country obsCASFR)\n",
    "    obs_filtered = all_obs_df[all_obs_df['Country'].isin(valid_c_set)]\n",
    "\n",
    "    # Convert all observed period data to cohort\n",
    "    cohort_df = period_to_cohort(obs_filtered)\n",
    "\n",
    "    # Add metadata columns\n",
    "    cohort_df['JumpOffYear'] = joy\n",
    "    cohort_df['Method'] = METHOD_NAME\n",
    "    cohort_df['Key'] = cohort_df['Method'] + '_' + cohort_df['Country'].astype(str)\n",
    "\n",
    "    obs_cohort_dfs.append(cohort_df)\n",
    "\n",
    "obsCASFR = pd.concat(obs_cohort_dfs, ignore_index=True)\n",
    "print(f\"obsCASFR shape: {obsCASFR.shape}\")\n",
    "print(f\"Columns: {list(obsCASFR.columns)}\")\n",
    "obsCASFR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/dl_forecasts_cohort_fewer_ages.csv (477210 rows)\n",
      "Saved: ../data/dl_obs_cohort_fewer_ages.csv (390420 rows)\n"
     ]
    }
   ],
   "source": [
    "predCASFR.to_csv('../data/dl_forecasts_cohort_fewer_ages.csv', index=False)\n",
    "obsCASFR.to_csv('../data/dl_obs_cohort_fewer_ages.csv', index=False)\n",
    "\n",
    "print(f\"Saved: ../data/dl_forecasts_cohort_fewer_ages.csv ({predCASFR.shape[0]} rows)\")\n",
    "print(f\"Saved: ../data/dl_obs_cohort_fewer_ages.csv ({obsCASFR.shape[0]} rows)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-fert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
