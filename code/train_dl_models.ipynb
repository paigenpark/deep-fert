{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning for Fertility Prediction (DLMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os as os\n",
    "tfkl = tf.keras.layers\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_functions' from '/Users/paigepark/Library/Mobile Documents/com~apple~CloudDocs/repos/deep-fert/code/training_functions.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import training_functions\n",
    "import importlib\n",
    "\n",
    "importlib.reload(training_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "asfr_training = np.loadtxt('../data/asfr_training.txt')\n",
    "asfr_test = np.loadtxt('../data/asfr_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75936, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asfr_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geos_key = np.load('../data/geos_key.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Country Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models are those used in the paper to produce all of main figures/table in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "train_prepped = training_functions.prep_data(asfr_training, mode=\"train\", changeratetolog=False)\n",
    "test_prepped = training_functions.prep_data(asfr_test, mode=\"test\", changeratetolog=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proper geography input dimension for model set up \n",
    "unique_vals = tf.unique(asfr_training[:, 0]).y\n",
    "country_geo_dim = np.array(tf.size(unique_vals)).item()\n",
    "country_geo_dim = country_geo_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.e+00, 1.e-05, 2.e-05])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.partition(np.unique(asfr_training[:,3]), 3)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 0.0024 - val_loss: 7.0921e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 2/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 7.4081e-04 - val_loss: 6.3446e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 3/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 4.7306e-04 - val_loss: 3.9262e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 4/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 2.7625e-04 - val_loss: 2.8674e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 5/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 2.0035e-04 - val_loss: 1.9285e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 6/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 1.5680e-04 - val_loss: 2.0340e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 7/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 1.2976e-04 - val_loss: 1.9185e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 8/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 1.1328e-04 - val_loss: 1.4777e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 9/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 1.0147e-04 - val_loss: 1.6466e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 10/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 9.1654e-05 - val_loss: 1.4667e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 11/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 8.3258e-05 - val_loss: 1.3770e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 12/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 7.6981e-05 - val_loss: 1.3411e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 13/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 7.1410e-05 - val_loss: 1.2164e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 14/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 6.7037e-05 - val_loss: 1.2918e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 15/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 6.3104e-05 - val_loss: 1.6102e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 16/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 5.9822e-05 - val_loss: 1.1462e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 17/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 5.7297e-05 - val_loss: 1.0926e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 18/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 5.4258e-05 - val_loss: 1.1912e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 19/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 5.2508e-05 - val_loss: 1.0798e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 20/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 5.0414e-05 - val_loss: 1.1786e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 21/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.8534e-05 - val_loss: 1.1230e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 22/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.7079e-05 - val_loss: 1.0618e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 23/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.5588e-05 - val_loss: 9.8463e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 24/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.4383e-05 - val_loss: 9.8073e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 25/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.2945e-05 - val_loss: 9.4549e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 26/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 4.2206e-05 - val_loss: 9.0392e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 27/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.0909e-05 - val_loss: 8.3097e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 28/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.9961e-05 - val_loss: 7.9217e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 29/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 3.8731e-05 - val_loss: 9.2859e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 30/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.8468e-05 - val_loss: 8.3375e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.7703e-05 - val_loss: 8.1099e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 32/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.4463e-05 - val_loss: 7.8752e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 33/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.4275e-05 - val_loss: 8.2758e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 34/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.4071e-05 - val_loss: 8.6931e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.4037e-05 - val_loss: 8.5850e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 36/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.3070e-05 - val_loss: 8.1631e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 37/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.2821e-05 - val_loss: 8.3193e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.2594e-05 - val_loss: 8.0800e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 39/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.2577e-05 - val_loss: 8.0604e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 40/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.2532e-05 - val_loss: 7.9651e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "1405/1405 - 5s - 3ms/step - loss: 3.2662e-05 - val_loss: 8.1979e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 42/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.2660e-05 - val_loss: 8.0196e-05 - learning_rate: 3.9063e-06\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "\u001b[1m2373/2373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250us/step\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step\n",
      "Iteration 1 complete\n",
      "Epoch 1/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 0.0018 - val_loss: 6.6973e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 2/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 5.9196e-04 - val_loss: 4.2982e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 3/50\n",
      "1405/1405 - 7s - 5ms/step - loss: 3.2027e-04 - val_loss: 3.7974e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 4/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 2.2629e-04 - val_loss: 2.5060e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 5/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 1.6871e-04 - val_loss: 1.6252e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 6/50\n",
      "1405/1405 - 10s - 7ms/step - loss: 1.3511e-04 - val_loss: 1.8331e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 7/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 1.1496e-04 - val_loss: 1.7237e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 8/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 1.0052e-04 - val_loss: 1.4813e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 9/50\n",
      "1405/1405 - 4s - 3ms/step - loss: 8.9096e-05 - val_loss: 1.3058e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 10/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 8.1667e-05 - val_loss: 1.4718e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 11/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 7.4306e-05 - val_loss: 1.0468e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 12/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 6.7926e-05 - val_loss: 1.2264e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 13/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 6.2660e-05 - val_loss: 9.1170e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 14/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 5.9121e-05 - val_loss: 1.0448e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 15/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 5.5525e-05 - val_loss: 1.1871e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1405/1405 - 5s - 4ms/step - loss: 5.2594e-05 - val_loss: 1.3068e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 17/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.7413e-05 - val_loss: 1.0132e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 4.6365e-05 - val_loss: 8.9066e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.6017e-05 - val_loss: 9.2982e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.5167e-05 - val_loss: 8.5913e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.4104e-05 - val_loss: 9.4413e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 4.4042e-05 - val_loss: 8.3396e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.3787e-05 - val_loss: 8.6399e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.2935e-05 - val_loss: 8.2418e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 4.2674e-05 - val_loss: 8.6723e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.2083e-05 - val_loss: 8.9800e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.1480e-05 - val_loss: 7.3718e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 4.1423e-05 - val_loss: 7.5562e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.0451e-05 - val_loss: 8.8321e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1405/1405 - 5s - 3ms/step - loss: 4.0531e-05 - val_loss: 8.9907e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "1405/1405 - 5s - 3ms/step - loss: 3.9505e-05 - val_loss: 8.4158e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.9070e-05 - val_loss: 8.3195e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.9314e-05 - val_loss: 7.6341e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 34/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.9130e-05 - val_loss: 8.0703e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 35/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.9304e-05 - val_loss: 8.0238e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.8539e-05 - val_loss: 8.0504e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 37/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 3.8676e-05 - val_loss: 8.0915e-05 - learning_rate: 3.9063e-06\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\u001b[1m2373/2373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261us/step\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step\n",
      "Iteration 2 complete\n",
      "Epoch 1/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 0.0023 - val_loss: 8.4255e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 2/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 7.2419e-04 - val_loss: 7.4785e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 3/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.7531e-04 - val_loss: 4.6889e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 4/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 2.7800e-04 - val_loss: 2.9369e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 5/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 1.9926e-04 - val_loss: 2.0906e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 6/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 1.5656e-04 - val_loss: 1.7353e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 7/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 1.3121e-04 - val_loss: 1.6394e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 8/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 1.1297e-04 - val_loss: 1.4574e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 9/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 9.9030e-05 - val_loss: 1.1431e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 10/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 8.8989e-05 - val_loss: 1.4790e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 11/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 8.0511e-05 - val_loss: 1.0515e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 12/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 7.3435e-05 - val_loss: 1.0615e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 13/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 6.8627e-05 - val_loss: 1.0763e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 14/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 6.4660e-05 - val_loss: 1.0097e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 15/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 6.1421e-05 - val_loss: 1.0480e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 16/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 5.8505e-05 - val_loss: 8.9324e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 17/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 5.6294e-05 - val_loss: 8.0157e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 18/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 5.3939e-05 - val_loss: 9.6898e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 19/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 5.2332e-05 - val_loss: 8.6992e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1405/1405 - 5s - 4ms/step - loss: 5.1096e-05 - val_loss: 1.0267e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 21/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.5981e-05 - val_loss: 9.3588e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.5509e-05 - val_loss: 9.6704e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.5236e-05 - val_loss: 9.2760e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "1405/1405 - 6s - 5ms/step - loss: 4.4054e-05 - val_loss: 8.7324e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.3700e-05 - val_loss: 7.9925e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.3698e-05 - val_loss: 8.7235e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.3230e-05 - val_loss: 8.9283e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.3153e-05 - val_loss: 8.6143e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.2623e-05 - val_loss: 8.7413e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 30/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.3218e-05 - val_loss: 8.9739e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.2995e-05 - val_loss: 8.7314e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 32/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.2829e-05 - val_loss: 8.7768e-05 - learning_rate: 3.9063e-06\n",
      "Epoch 33/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.2702e-05 - val_loss: 8.7274e-05 - learning_rate: 3.9063e-06\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.2928e-05 - val_loss: 8.6728e-05 - learning_rate: 3.9063e-06\n",
      "Epoch 35/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.2990e-05 - val_loss: 8.7380e-05 - learning_rate: 9.7656e-07\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "\u001b[1m2373/2373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262us/step\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step\n",
      "Iteration 3 complete\n",
      "Epoch 1/50\n",
      "1405/1405 - 8s - 5ms/step - loss: 0.0021 - val_loss: 7.6890e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 2/50\n",
      "1405/1405 - 7s - 5ms/step - loss: 7.3887e-04 - val_loss: 7.3805e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 3/50\n",
      "1405/1405 - 7s - 5ms/step - loss: 4.7323e-04 - val_loss: 4.6235e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 4/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 2.8055e-04 - val_loss: 2.9970e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 5/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 2.1086e-04 - val_loss: 2.3080e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 6/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 1.6479e-04 - val_loss: 1.7129e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 7/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 1.3538e-04 - val_loss: 1.9533e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 8/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 1.1688e-04 - val_loss: 1.4934e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 9/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 1.0283e-04 - val_loss: 1.1600e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 10/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 9.2338e-05 - val_loss: 1.3714e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 11/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 8.3097e-05 - val_loss: 1.0957e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 12/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 7.6266e-05 - val_loss: 1.1343e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 13/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 7.1681e-05 - val_loss: 1.0308e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 14/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 6.6301e-05 - val_loss: 1.1284e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 15/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 6.3429e-05 - val_loss: 1.2446e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 16/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 6.0621e-05 - val_loss: 9.7009e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 17/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 5.7942e-05 - val_loss: 8.9247e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 18/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 5.5880e-05 - val_loss: 1.0068e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 19/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 5.3929e-05 - val_loss: 8.5320e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 20/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 5.2463e-05 - val_loss: 1.0102e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 21/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 5.0530e-05 - val_loss: 1.0447e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.9176e-05 - val_loss: 9.9418e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 23/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.4791e-05 - val_loss: 8.4857e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.4436e-05 - val_loss: 8.7326e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.3882e-05 - val_loss: 8.1793e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.3459e-05 - val_loss: 8.1192e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.2743e-05 - val_loss: 7.8702e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "1405/1405 - 5s - 4ms/step - loss: 4.2379e-05 - val_loss: 7.3806e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.1791e-05 - val_loss: 8.1416e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.2038e-05 - val_loss: 7.9616e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.1296e-05 - val_loss: 8.0622e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 32/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.0788e-05 - val_loss: 8.0481e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.0683e-05 - val_loss: 7.6980e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.0049e-05 - val_loss: 7.7892e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 35/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.0199e-05 - val_loss: 8.0996e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 36/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.0064e-05 - val_loss: 8.0816e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "1405/1405 - 6s - 4ms/step - loss: 3.9707e-05 - val_loss: 7.9781e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 38/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 3.9881e-05 - val_loss: 7.9029e-05 - learning_rate: 3.9063e-06\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "\u001b[1m2373/2373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258us/step\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step\n",
      "Iteration 4 complete\n",
      "Epoch 1/50\n",
      "1405/1405 - 7s - 5ms/step - loss: 0.0017 - val_loss: 6.8457e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 2/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 6.2710e-04 - val_loss: 5.2647e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 3/50\n",
      "1405/1405 - 6s - 5ms/step - loss: 3.5887e-04 - val_loss: 4.1051e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 4/50\n",
      "1405/1405 - 6s - 5ms/step - loss: 2.5146e-04 - val_loss: 2.8178e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 5/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 1.8335e-04 - val_loss: 1.7304e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 6/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 1.4105e-04 - val_loss: 2.0798e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 7/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 1.2025e-04 - val_loss: 1.8694e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 8/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 1.0603e-04 - val_loss: 1.4802e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 9/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 9.4085e-05 - val_loss: 1.4470e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 10/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 8.5188e-05 - val_loss: 1.7798e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 11/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 7.7271e-05 - val_loss: 1.1561e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 12/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 7.2202e-05 - val_loss: 1.3423e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 13/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 6.7376e-05 - val_loss: 8.8379e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 14/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 6.3552e-05 - val_loss: 9.3596e-05 - learning_rate: 1.0000e-03\n",
      "Epoch 15/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 6.0402e-05 - val_loss: 1.0666e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1405/1405 - 6s - 5ms/step - loss: 5.7964e-05 - val_loss: 1.1429e-04 - learning_rate: 1.0000e-03\n",
      "Epoch 17/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 5.2666e-05 - val_loss: 1.0287e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 5.1763e-05 - val_loss: 1.0622e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1405/1405 - 6s - 4ms/step - loss: 5.1006e-05 - val_loss: 9.7591e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.9533e-05 - val_loss: 1.0028e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.9236e-05 - val_loss: 1.0171e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.9227e-05 - val_loss: 9.1883e-05 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "1405/1405 - 6s - 4ms/step - loss: 4.8766e-05 - val_loss: 9.6666e-05 - learning_rate: 1.5625e-05\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m2373/2373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265us/step\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step\n",
      "Iteration 5 complete\n"
     ]
    }
   ],
   "source": [
    "# run all country model\n",
    "for i in range(1,6):\n",
    "    # Set reproducible seeds per iteration\n",
    "    np.random.seed(i)\n",
    "    tf.random.set_seed(i)\n",
    "    random.seed(i)\n",
    "    os.environ['PYTHONHASHSEED'] = str(i)\n",
    "\n",
    "    model_country, loss_info_country = training_functions.run_deep_model(train_prepped, test_prepped, country_geo_dim, \n",
    "                                                                         epochs=50, \n",
    "                                                                         steps_per_epoch=1405, \n",
    "                                                                         lograte=False)\n",
    "\n",
    "    training_input_features = (tf.convert_to_tensor((asfr_training[:,1] - 1950) / (2015-1950), dtype=tf.float32),  # Normalized year\n",
    "                            tf.convert_to_tensor(asfr_training[:,2], dtype=tf.float32),  # Age\n",
    "                            tf.convert_to_tensor(asfr_training[:,0], dtype=tf.float32))  # Geo\n",
    "    \n",
    "    test_input_features = (tf.convert_to_tensor((asfr_test[:,1] - 1950) / (2015-1950), dtype=tf.float32),  # Normalized year\n",
    "                        tf.convert_to_tensor(asfr_test[:,2], dtype=tf.float32),  # Age\n",
    "                        tf.convert_to_tensor(asfr_test[:,0], dtype=tf.float32))  # Geo\n",
    "\n",
    "    training_predictions = model_country.predict(training_input_features)\n",
    "\n",
    "    test_predictions = model_country.predict(test_input_features)\n",
    "\n",
    "    inputs = np.delete(asfr_training, 3, axis=1)\n",
    "    training_predictions = np.column_stack((inputs, training_predictions))\n",
    "    inputs_test = np.delete(asfr_test, 3, axis=1)\n",
    "    test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "    model_country.save(f\"../models/dl_model_{i}.keras\")\n",
    "\n",
    "    np.savetxt(f\"../data/dl_fitted_{i}.txt\", training_predictions)\n",
    "    np.savetxt(f\"../data/dl_forecast_{i}.txt\", test_predictions)    \n",
    "\n",
    "    print(f\"Iteration {i} complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
